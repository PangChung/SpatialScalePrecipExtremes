<!--HOW TO COMPLETE THIS FORM:-->

<!--
1. Checkboxes in this document appear as follows: 

- [ ] This is a checkbox 

To check a checkbox, replace [ ] by [x], as follows: 

- [x] This is a checked checkbox 

Note that older versions of RStudio (versions lower than 1.3) may not create a formatted checkbox but will leave the original characters, i.e., literally "[ ]" or "[x]". It's fine to submit a PDF in this form.
 
2. For text answers, simply type the relevant text in the areas indicated. A blank line starts a new paragraph. 
 
3. Comments (like these instructions) provide additional instructions throughout the form. There is no need to remove them; they will not appear in the compiled document. 

4. If you are comfortable with Markdown syntax, you may choose to include any Markdown-compliant formatting in the form. For example, you may wish to include R code chunks and compile this document in R Markdown.
-->

This form documents the artifacts associated with the article (i.e., the data and code supporting the computational findings) and describes how to reproduce the findings.


# Part 1: Data

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).


<!--
If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the Code section. Otherwise, continue.
-->

- [x] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.

<!-- If data are simulated using random number generation, please be sure to set the random number seed in the code you provide -->

## Abstract
The raw data set used in this paper consists of two parts; the first part contains observed daily precipitation and precipitation data in millimeters and daily temperature averages in degrees Celsius from 125 monitoring stations
in the Danube river basin (Europe) and from 2229 monitoring stations in the Mississippi
river basin (North America), which is publicly available from the [Global Historical
Climatology Network (GHCN)](https://www.ncei.noaa.gov/) for the period 1965–2015. The second part consists of the predicted daily tempearture output from the sixth Coupled Model Intercomparison Project
(CMIP6) between 2016--2100, which is publicly available on the [Copernicus data base](https://www.copernicus.eu/en/access-data). 

<!--
Provide a short (< 100 words), high-level description of the data
-->

## Availability


- [x] Data **are** publicly available.
- [ ] Data **cannot be made** publicly available.

If the data are publicly available, see the *Publicly available data* section. Otherwise, see the *Non-publicly available data* section, below.

### Publicly available data

- [x] Data are available online at: [Global Historical
Climatology Network (GHCN)](https://www.ncei.noaa.gov/) and [Copernicus data base](https://www.copernicus.eu/en/access-data). The R data files as a product of our analysis are available at the [Google drive](https://drive.google.com/drive/folders/1gbsgV_kNmaPSnU7HuMELBuYNaS5NNADB?usp=sharing).

- [ ] Data are available as part of the paper’s supplementary material.

- [ ] Data are publicly available by request, following the process described here:

- [ ] Data are or will be made available through some other mechanism, described here:


<!-- If data are available by request to the authors or some other data owner, please make sure to explain the process of requesting access to the data. -->

### Non-publicly available data

<!--
The Journal of the American Statistical Association requires authors to make data accompanying their papers available to the scientific community except in cases where: 1) public sharing of data would be impossible, 2) suitable synthetic data are provided which allow the main analyses to be replicated (recognizing that results may differ from the "real" data analyses), and 3) the scientific value of the results and methods outweigh the lack of reproducibility.

Please discuss the lack of publicly available data. For example:
-	why data sharing is not possible,
-	what synthetic data are provided, and 
-	why the value of the paper's scientific contribution outweighs the lack of reproducibility.
-->

## Description
We provide the data in R Data format, which are hosted on the Google drive as mentioned above. One should download the data first to proceed with the code accompanying this paper.

### File format(s)

<!--
Check all that apply
-->
- [ ] CSV or other plain text.
- [x] Software-specific binary format (.Rda, Python pickle, etc.): .RData
- [ ] Standardized binary format (e.g., netCDF, HDF5, etc.): 
- [ ] Other (please specify):

### Data dictionary

<!--
A data dictionary provides information that allows users to understand the meaning, format, and use of the data.
-->

- [x] Provided by authors in the following file(s): 
* marginal_fit.RData
	+ date.ts: vector of dates for the observed precipitation and temperatures in the period 1965--2015.
	+ est.shape.gpd: estiamted shape parameter in the marginal GPD model for those two regions, danube and mississippi.
	+ precip.ts.df: list of the precipitation data in the two regions.
	+ station.df: information about the monitoring stations including altitude, latitude, longitude.
	+ tep: a list of vectors of tempearture coviarite derived from observed tempeatures in each region.
	+ U.data: pesudo-uniform scores of the precipitation data based on the marginal fit.
* marginal_model_for_danube(or mississippi).RData
	+ results.bin: object of the binary GAM model in each region. 
	+ results.gam: object of the Gamma GAM model in each region.
	+ results.gpd: object of the GPD GAM model in each region.
* result_pot_10_moving(2).Rdata
	+ estimates.bootstrap.list: list of the estimates derived from the bootstrap scheme in the two regions.
	+ estimates.list: list of the estimates based on the original data
	+ result_pot_10_moving.Rdata contains the estimates where $\theta$=$\hat\xi$.
	+ result_pot_10_moving.Rdata contains the estimates where $\theta$=1$.
* temperature_covariate.Rdata
	+ data.mean.obs.hist.day: list of temperature daily averages for each region based on the observed temperatures.
	+ data.mean.tep.245.day: list of temperature daily averages for each region based on the future (2016--2100) predictions from the climate model outputs under the Shared Socioeconomic Pathways (SSPs) 2-4.5.
	+ data.mean.tep.hist.day: list of temperature daily averages for each region based on the historical runs of the climate model outputs
	+ data.mean.tep.585.day: list of temperature daily averages for each region based on the future (2016--2100) predictions from the climate model outputs under the Shared Socioeconomic Pathways (SSPs) 5-8.5.
	

- [ ] Data file(s) is(are) self-describing (e.g., netCDF files)
- [ ] Available at the following URL: 

### Additional Information (optional)

<!-- 
OPTIONAL: Provide any additional details that would be helpful in understanding the data. If relevant, please provide unique identifier/DOI/version information and/or license/terms of use.
-->

# Part 2: Code

## Abstract

<!--
Provide a short (< 100 words), high-level description of the code. If necessary, more details can be provided in files that accompany the code. If no code is provided, please state this and say why (e.g., if the paper contains no computational work).
-->

## Description

### Code format(s)

<!--
Check all that apply
-->
- [x] Script files
    - [x] R
    - [ ] Python
    - [ ] Matlab
    - [ ] Other: 
- [x] Package
    - [x] R
    - [ ] Python
    - [ ] MATLAB toolbox
    - [ ] Other: 
- [ ] Reproducible report 
    - [ ] R Markdown
    - [ ] Jupyter notebook
    - [ ] Other:
- [ ] Shell script
- [ ] Other (please specify): 

### Supporting software requirements

#### Version of primary software used

R version 4.2.1
<!--
(e.g., R version 3.6.0)
-->

#### Libraries and dependencies used by the code
* R Packages
	+ parallel version 4.2.1
	+ evd version 2.3-6
	+ fields version 13.3
	+ mgcv version 1.8-40
	+ evgam version 1.0.0
	+ mvPotST (developed based on mvPot version 0.1.5)
	+ lubridate version 1.8.0
<!--
Include version numbers (e.g., version numbers for any R or Python packages used)
-->

### Supporting system/hardware requirements (optional)

<!--
OPTIONAL: System/hardware requirements including operating system with version number, access to cluster, GPUs, etc.
-->

### Parallelization used

- [ ] No parallel code used
- [x] Multi-core parallelization on a single machine/node
    - Number of cores used: 28
- [ ] Multi-machine/multi-node parallelization 
    - Number of nodes and cores used: 

### License

- [x] MIT License (default)
- [ ] BSD 
- [ ] GPL v3.0
- [ ] Creative Commons
- [ ] Other: (please specify)


### Additional information (optional)

<!--
OPTIONAL: By default, submitted code will be published on the JASA GitHub repository (http://github.com/JASA-ACS) as well as in the supplementary material. Authors are encouraged to also make their code available in a public code repository, such as on GitHub, GitLab, or BitBucket. If relevant, please provide unique identifier/DOI/version information (e.g., a Git commit ID, branch, release, or tag). If the code and workflow are provided together, this section may be omitted, with information provided in the "Location" section below.
-->

# Part 3: Reproducibility workflow

<!--
The materials provided should provide a straightforward way for reviewers and readers to reproduce analyses with as few steps as possible. 
-->

## Scope

The provided workflow reproduces:

- [ ] Any numbers provided in text in the paper
- [x] The computational method(s) presented in the paper (i.e., code is provided that implements the method(s))
- [x] All tables and figures in the paper
- [ ] Selected tables and figures in the paper, as explained and justified below:

## Workflow

### Location

The workflow is available:

<!--
Check all that apply, and in the case of a Git repository include unique identifier, such as specific commit ID, branch, release, or tag.
-->
- [ ] As part of the paper’s supplementary material.
- [x] In this Git repository: https://github.com/PangChung/SpatialScalePrecipExtremes
- [ ] Other (please specify):

<!--
Indicate where the materials (generally including the code, unless in a separate location and indicated in the previous section) are available. We strongly encourage authors to place their materials (but not large datasets) in a Git repository hosted on a site such as GitHub, GitLab, or BitBucket. If the repository is private during the review process, please indicate the location where it will be available publicly upon publication, and also include the materials as a zip file (e.g., obtained directly from the Git hosting site) as supplementary materials.
-->


### Format(s)

<!--
Check all that apply
-->
- [ ] Single master code file 
- [ ] Wrapper (shell) script(s)
- [ ] Self-contained R Markdown file, Jupyter notebook, or other literate programming approach
- [ ] Text file (e.g., a readme-style file) that documents workflow
- [ ] Makefile
- [x] Other (more detail in *Instructions* below)

### Instructions
The main analysis are performed using the code in the file main.R. To fit the dependence model presented in the paper, we provide the R script Dependence_Model_Fit.R. The file extra_functions.R contains functions used in the file, main.R, and file, Dependence_Model_Fit.R.

The package mvPotST includes functions and methods to perform the dependence fit and run simulations. The reader should install the package, mvPotST,first in order to proceed the analysis presented in our R code.

<!--
Describe how to use the materials provided to reproduce analyses in the manuscript. Additional details can be provided in file(s) accompanying the reproducibility materials. If no workflow is provided, please state this and say why (e.g., if the paper contains no computational work).
-->

### Expected run-time

Approximate time needed to reproduce the analyses on a standard desktop machine:

- [ ] < 1 minute
- [ ] 1-10 minutes
- [ ] 10-60 minutes
- [ ] 1-8 hours
- [ ] > 8 hours
- [x] Not feasible to run on a desktop machine, as described here:
The analysis includes performing nonparametric bootstrap to produce confidence intervals, where we used computer clusters. Moreover, To fit the marginal model as well as the dependence model, we strongly advice readers to use a workstation to run the code.

### Additional information (optional)

<!--
OPTIONAL: Additional documentation provided (e.g., R package vignettes, demos or other examples) that show how to use the provided code/software in other settings.
-->

# Notes (optional)

<!--
OPTIONAL: Any other relevant information not covered on this form. If reproducibility materials are not publicly available at the time of submission, please provide information here on how the reviewers can view the materials.
-->
